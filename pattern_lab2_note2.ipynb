{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## importing pad_sequences,to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OTvTCz85ispZ"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "###read from step1,2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reading   vocab , training data and augmanted data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2WPG0pA5cbB",
        "outputId": "48846712-b2c2-40f0-fea0-ce49e546c217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['a' '1']\n",
            " ['.' '2']\n",
            " ['in' '3']\n",
            " ...\n",
            " ['non-working' '2727']\n",
            " ['startseq' '2728']\n",
            " ['endseq' '2729']]\n",
            "(3000, 2048) 3000\n",
            "3000\n"
          ]
        }
      ],
      "source": [
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np###read from step1,2\n",
        "vocabulary=np.load('./vocabulary (1).npy')\n",
        "##output of CNN without the prediction layer or any additional FC layers size(2048,0)\n",
        "#images_features=np.load('./training_features_after_pooling.npy')\n",
        "images_features=np.load('./augmented_training_features_after_pooling.npy')\n",
        "#images_features = np.concatenate((images_features_1, images_features_2), axis=0)\n",
        "#read from tokeniszed captions\n",
        "captions_dict=np.load('./training_tokenized_captions.npy')\n",
        "#captions_dict = np.concatenate((captions_dict, captions_dict), axis=0)\n",
        "print(vocabulary)\n",
        "print(images_features.shape,len(images_features))\n",
        "print(len(captions_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4NCLZBrOLqo",
        "outputId": "52dce262-91d2-44c2-e7ef-f2ed8a2f8073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3000, 2048)\n",
            "(3000, 37)\n"
          ]
        }
      ],
      "source": [
        "print(images_features.shape)\n",
        "print(captions_dict.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# generation of data passed to the model for training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QfXAMPgf4_Xt"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = len(vocabulary)\n",
        "MAX_LEN=37\n",
        "def generator(images, caption):\n",
        "    n_samples = 0\n",
        "\n",
        "    X = []\n",
        "    y_in = []\n",
        "    y_out = []\n",
        "\n",
        "    for i in range(0,len(images_features)):\n",
        "        for j in range (1,len(captions_dict[i])-1):\n",
        "\n",
        "            X.append(images_features[i])\n",
        "            in_seq= [captions_dict[i][:j]]\n",
        "            out_seq = captions_dict[i][j]\n",
        "            in_seq = pad_sequences(in_seq, maxlen=MAX_LEN, padding='post', truncating='post')[0]\n",
        "            # out_seq = to_categorical(int(out_seq), num_classes=VOCAB_SIZE)[0]\n",
        "            out = np.zeros(VOCAB_SIZE)\n",
        "            out[out_seq-1]=1\n",
        "\n",
        "            y_in.append(in_seq)\n",
        "            y_out.append(out)\n",
        "\n",
        "    return X, y_in, y_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTm5pMKS5CJY",
        "outputId": "1c0ecb19-75df-4f33-e173-dd8f6c8bf3f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(105000, 105000, 105000)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X, y_in, y_out = generator(images_features, captions_dict)\n",
        "len(X), len(y_in), len(y_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQIviVMG5ELv",
        "outputId": "191c2915-cbb7-4293-c5b9-7bb9af0ad21b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((105000, 2048), (105000, 37), (105000, 2729))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = np.array(X)\n",
        "y_in = np.array(y_in, dtype='float64')\n",
        "y_out = np.array(y_out, dtype='float64')\n",
        "X.shape, y_in.shape, y_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "RCshYeNefCoB",
        "outputId": "e3d5570a-b345-44f4-83e9-4bbea7fce03d"
      },
      "outputs": [],
      "source": [
        "np.save('X.npy', X)\n",
        "np.save('y_in.npy', y_in)\n",
        "np.save('y_out.npy', y_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9q03TBmkjA2T"
      },
      "outputs": [],
      "source": [
        "vocabulary=np.load('./vocabulary (1).npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LnlfPilYfSHs"
      },
      "outputs": [],
      "source": [
        "X = np.load('./X.npy')\n",
        "y_in = np.load('./y_in.npy')\n",
        "y_out = np.load('./y_out.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# model structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "L52KoZ0z5Ri8"
      },
      "outputs": [],
      "source": [
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import add\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Dense, Flatten,Input, Convolution2D, Dropout, LSTM, TimeDistributed, Embedding, Bidirectional, Activation, RepeatVector,Concatenate\n",
        "from keras.models import Sequential, Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN4i41hl5Tij",
        "outputId": "116f3e83-57ec-4e18-ac71-5c25b4ad1b7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                131136    \n",
            "                                                                 \n",
            " repeat_vector (RepeatVecto  (None, 37, 64)            0         \n",
            " r)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 37, 64)            0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 131136 (512.25 KB)\n",
            "Trainable params: 131136 (512.25 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 64)          174656    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, None, 256)         328704    \n",
            "                                                                 \n",
            " time_distributed (TimeDist  (None, None, 64)          16448     \n",
            " ributed)                                                        \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, None, 64)          0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 519808 (1.98 MB)\n",
            "Trainable params: 519808 (1.98 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " embedding_input (InputLaye  [(None, None)]               0         []                            \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " dense_input (InputLayer)    [(None, 2048)]               0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, None, 64)             174656    ['embedding_input[0][0]']     \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 64)                   131136    ['dense_input[0][0]']         \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (None, None, 256)            328704    ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " repeat_vector (RepeatVecto  (None, 37, 64)               0         ['dense[0][0]']               \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " time_distributed (TimeDist  (None, None, 64)             16448     ['lstm[0][0]']                \n",
            " ributed)                                                                                         \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 37, 64)               0         ['repeat_vector[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, None, 64)             0         ['time_distributed[0][0]']    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 37, 128)              0         ['dropout[0][0]',             \n",
            "                                                                     'dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               (None, 37, 128)              131584    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               (None, 512)                  1312768   ['lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 2729)                 1399977   ['lstm_2[0][0]']              \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 2729)                 0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3495273 (13.33 MB)\n",
            "Trainable params: 3495273 (13.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "embedding_size = 64\n",
        "max_len = 37\n",
        "vocab_size = len(vocabulary)\n",
        "\n",
        "image_model = Sequential()\n",
        "\n",
        "image_model.add(Dense(embedding_size, input_shape=(2048,), activation='relu'))\n",
        "image_model.add(RepeatVector(max_len))\n",
        "image_model.add(Dropout(0.5))\n",
        "image_model.summary()\n",
        "\n",
        "# Define LSTM model\n",
        "language_model = Sequential()\n",
        "language_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size))\n",
        "language_model.add(LSTM(256, return_sequences=True))\n",
        "language_model.add(TimeDistributed(Dense(embedding_size)))\n",
        "language_model.add(Dropout(0.5))\n",
        "language_model.summary()\n",
        "\n",
        "conca = Concatenate()([image_model.output, language_model.output])\n",
        "x = LSTM(128, return_sequences=True)(conca)\n",
        "x = LSTM(512, return_sequences=False)(x)\n",
        "x = Dense(vocab_size)(x)\n",
        "out = Activation('softmax')(x)\n",
        "model = Model(inputs=[image_model.input, language_model.input], outputs = out)\n",
        "\n",
        "# model.load_weights(\"../input/model_weights.h5\")\n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H9d3QRlWEmk"
      },
      "source": [
        "# loading  the trained model for training if trained before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIHAlpJ2OwmH",
        "outputId": "b8b87549-5e31-4405-cd21-b5918df2579d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " embedding_input (InputLaye  [(None, None)]               0         []                            \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " dense_input (InputLayer)    [(None, 2048)]               0         []                            \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, None, 64)             174656    ['embedding_input[0][0]']     \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 64)                   131136    ['dense_input[0][0]']         \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 (None, None, 256)            328704    ['embedding[0][0]']           \n",
            "                                                                                                  \n",
            " repeat_vector (RepeatVecto  (None, 37, 64)               0         ['dense[0][0]']               \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " time_distributed (TimeDist  (None, None, 64)             16448     ['lstm[0][0]']                \n",
            " ributed)                                                                                         \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 37, 64)               0         ['repeat_vector[0][0]']       \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, None, 64)             0         ['time_distributed[0][0]']    \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 37, 128)              0         ['dropout[0][0]',             \n",
            "                                                                     'dropout_1[0][0]']           \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               (None, 37, 128)              131584    ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               (None, 512)                  1312768   ['lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 2729)                 1399977   ['lstm_2[0][0]']              \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 2729)                 0         ['dense_2[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3495273 (13.33 MB)\n",
            "Trainable params: 3495273 (13.33 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load the model\n",
        "model = load_model(\"trained_lstm_new.h5\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# training the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXfFceZA5UwQ",
        "outputId": "e753e527-69f1-48b1-c3bc-00957b84ee23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "2838/2838 [==============================] - 58s 18ms/step - loss: 1.4544 - accuracy: 0.7629\n",
            "Epoch 2/20\n",
            "2838/2838 [==============================] - 44s 15ms/step - loss: 1.4485 - accuracy: 0.7637\n",
            "Epoch 3/20\n",
            "2838/2838 [==============================] - 44s 15ms/step - loss: 1.4450 - accuracy: 0.7648\n",
            "Epoch 4/20\n",
            "2838/2838 [==============================] - 44s 16ms/step - loss: 1.4421 - accuracy: 0.7650\n",
            "Epoch 5/20\n",
            "2838/2838 [==============================] - 43s 15ms/step - loss: 1.4373 - accuracy: 0.7653\n",
            "Epoch 6/20\n",
            "2838/2838 [==============================] - 44s 15ms/step - loss: 1.4295 - accuracy: 0.7662\n",
            "Epoch 7/20\n",
            "2838/2838 [==============================] - 44s 15ms/step - loss: 1.4268 - accuracy: 0.7670\n",
            "Epoch 8/20\n",
            "2838/2838 [==============================] - 43s 15ms/step - loss: 1.4273 - accuracy: 0.7671\n",
            "Epoch 9/20\n",
            "2838/2838 [==============================] - 44s 16ms/step - loss: 1.4339 - accuracy: 0.7671\n",
            "Epoch 10/20\n",
            "2838/2838 [==============================] - 43s 15ms/step - loss: 1.4279 - accuracy: 0.7666\n",
            "Epoch 11/20\n",
            "2838/2838 [==============================] - 44s 15ms/step - loss: 1.4211 - accuracy: 0.7686\n",
            "Epoch 12/20\n",
            "2838/2838 [==============================] - 43s 15ms/step - loss: 1.4157 - accuracy: 0.7682\n",
            "Epoch 13/20\n",
            "2838/2838 [==============================] - 44s 15ms/step - loss: 1.4137 - accuracy: 0.7697\n",
            "Epoch 14/20\n",
            "2838/2838 [==============================] - 43s 15ms/step - loss: 1.4081 - accuracy: 0.7698\n",
            "Epoch 15/20\n",
            "2838/2838 [==============================] - 43s 15ms/step - loss: 1.4053 - accuracy: 0.7702\n",
            "Epoch 16/20\n",
            "2838/2838 [==============================] - 44s 15ms/step - loss: 1.4064 - accuracy: 0.7696\n",
            "Epoch 17/20\n",
            "2838/2838 [==============================] - 43s 15ms/step - loss: 1.4112 - accuracy: 0.7705\n",
            "Epoch 18/20\n",
            "2838/2838 [==============================] - 44s 16ms/step - loss: 1.4097 - accuracy: 0.7710\n",
            "Epoch 19/20\n",
            "2838/2838 [==============================] - 44s 15ms/step - loss: 1.3980 - accuracy: 0.7705\n",
            "Epoch 20/20\n",
            "2838/2838 [==============================] - 44s 15ms/step - loss: 1.3956 - accuracy: 0.7711\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78095a129090>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit([X, y_in], y_out, batch_size=37, epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# saving the trained model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "X4JyesyyT3vC",
        "outputId": "4ae6679e-f461-46ac-a151-b47476c26973"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_77fefe17-eab6-4fc8-aae5-71278b8a7749\", \"trained_lstm_new.h5\", 28027472)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Save the model to the local file system\n",
        "model.save(\"trained_lstm_new.h5\")\n",
        "# Download the saved model file\n",
        "from google.colab import files\n",
        "files.download(\"trained_lstm_new.h5\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
